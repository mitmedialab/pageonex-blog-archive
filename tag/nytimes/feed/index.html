<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>nytimes &#8211; PageOneX</title>
	<atom:link href="https://blog.pageonex.com/tag/nytimes/feed/" rel="self" type="application/rss+xml" />
	<link>https://blog.pageonex.com</link>
	<description>Coding front pages</description>
	<lastBuildDate>Wed, 20 Jun 2012 04:18:43 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.4.2</generator>
	<item>
		<title>Update Scraping script to scrape from many sources</title>
		<link>https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/</link>
					<comments>https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/#comments</comments>
		
		<dc:creator><![CDATA[pablo]]></dc:creator>
		<pubDate>Wed, 20 Jun 2012 04:18:43 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[Scraping]]></category>
		<category><![CDATA[elpais]]></category>
		<category><![CDATA[kiosko]]></category>
		<category><![CDATA[nytimes]]></category>
		<category><![CDATA[ruby]]></category>
		<category><![CDATA[scraper]]></category>
		<guid isPermaLink="false">http://montera34.org/pageonex/?p=47</guid>

					<description><![CDATA[I&#8217;ve made some changes to the script to scrape from different sources (http://kiosko.net, http:/nytimes.com, http://elpais.com) and other sources can be added easily, for each source there are two methods, build_source_issues and save_source_issues, the first method is to construct the URI of the issue image based on some pattern which different from source to another, and the other method is to scrape the images and save them on the disk in their specific folders. I&#8217;ve wrote some comments to clear some parts of&#8230; <a href="https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
		
					<wfw:commentRss>https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
	</channel>
</rss>
