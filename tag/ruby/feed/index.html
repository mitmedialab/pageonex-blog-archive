<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>ruby &#8211; PageOneX</title>
	<atom:link href="https://blog.pageonex.com/tag/ruby/feed/" rel="self" type="application/rss+xml" />
	<link>https://blog.pageonex.com</link>
	<description>Coding front pages</description>
	<lastBuildDate>Fri, 06 Jul 2012 00:19:10 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.4.2</generator>
	<item>
		<title>PageOneX Development Status</title>
		<link>https://blog.pageonex.com/2012/07/06/pageonex-development-status/</link>
					<comments>https://blog.pageonex.com/2012/07/06/pageonex-development-status/#respond</comments>
		
		<dc:creator><![CDATA[pablo]]></dc:creator>
		<pubDate>Fri, 06 Jul 2012 00:19:10 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[User Interface]]></category>
		<category><![CDATA[rails]]></category>
		<category><![CDATA[ruby]]></category>
		<category><![CDATA[ui]]></category>
		<guid isPermaLink="false">http://montera34.org/pageonex/?p=147</guid>

					<description><![CDATA[We are now is so close to the first Version 0.1, which will basically give the user the following features; to be able to create an account and creating a Thread, with basic info; name, start date, end date (in the same month, just for alpha version), description, choosing and number of newspaper, and Topics  to code with it and for each topic the user can add a color and description. Then user start to code&#8230; <a href="https://blog.pageonex.com/2012/07/06/pageonex-development-status/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
		
					<wfw:commentRss>https://blog.pageonex.com/2012/07/06/pageonex-development-status/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Update Scraping script to scrape from many sources</title>
		<link>https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/</link>
					<comments>https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/#comments</comments>
		
		<dc:creator><![CDATA[pablo]]></dc:creator>
		<pubDate>Wed, 20 Jun 2012 04:18:43 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[Scraping]]></category>
		<category><![CDATA[elpais]]></category>
		<category><![CDATA[kiosko]]></category>
		<category><![CDATA[nytimes]]></category>
		<category><![CDATA[ruby]]></category>
		<category><![CDATA[scraper]]></category>
		<guid isPermaLink="false">http://montera34.org/pageonex/?p=47</guid>

					<description><![CDATA[I&#8217;ve made some changes to the script to scrape from different sources (http://kiosko.net, http:/nytimes.com, http://elpais.com) and other sources can be added easily, for each source there are two methods, build_source_issues and save_source_issues, the first method is to construct the URI of the issue image based on some pattern which different from source to another, and the other method is to scrape the images and save them on the disk in their specific folders. I&#8217;ve wrote some comments to clear some parts of&#8230; <a href="https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
		
					<wfw:commentRss>https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>First Scraping script for Kiosko.net</title>
		<link>https://blog.pageonex.com/2012/06/13/first-scrapping-script-for-kiosko-net/</link>
					<comments>https://blog.pageonex.com/2012/06/13/first-scrapping-script-for-kiosko-net/#respond</comments>
		
		<dc:creator><![CDATA[pablo]]></dc:creator>
		<pubDate>Wed, 13 Jun 2012 20:06:11 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[Scraping]]></category>
		<category><![CDATA[kiosko]]></category>
		<category><![CDATA[newseum]]></category>
		<category><![CDATA[ruby]]></category>
		<category><![CDATA[scraper]]></category>
		<guid isPermaLink="false">http://montera34.org/pageonex/?p=31</guid>

					<description><![CDATA[Ahmd has been working on a scrapper in Ruby for the front Pages at Kiosko.net I&#8217;ve finished the scraping script, and it&#8217;s public on https://gist.github.com/2925910 to run the script just pass the file to ruby [ruby scraper.rb] and it will generate the folders (the directories is set for Linux, if you are on Windows you should modify them first), download the images(you can change the variable values in the get_issues method to get different newspapers), and write the&#8230; <a href="https://blog.pageonex.com/2012/06/13/first-scrapping-script-for-kiosko-net/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
		
					<wfw:commentRss>https://blog.pageonex.com/2012/06/13/first-scrapping-script-for-kiosko-net/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
