<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Scraping &#8211; PageOneX</title>
	<atom:link href="https://blog.pageonex.com/category/scraping/feed/" rel="self" type="application/rss+xml" />
	<link>https://blog.pageonex.com</link>
	<description>Coding front pages</description>
	<lastBuildDate>Fri, 06 Jul 2012 01:32:41 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.4.2</generator>
	<item>
		<title>Arab Spring Visualization with Processing + Inkscape</title>
		<link>https://blog.pageonex.com/2012/07/06/arab-spring-visualization-with-processing-inkscape/</link>
					<comments>https://blog.pageonex.com/2012/07/06/arab-spring-visualization-with-processing-inkscape/#comments</comments>
		
		<dc:creator><![CDATA[pablo]]></dc:creator>
		<pubDate>Fri, 06 Jul 2012 01:32:41 +0000</pubDate>
				<category><![CDATA[Scraping]]></category>
		<category><![CDATA[kiosko]]></category>
		<category><![CDATA[processing]]></category>
		<category><![CDATA[scraper]]></category>
		<guid isPermaLink="false">http://montera34.org/pageonex/?p=156</guid>

					<description><![CDATA[I&#8217;ve done this datavis on arab spring with processing + inkscape and here&#8217;s Pablo&#8217;s comments In order to see the highlighted areas front pages need to be less intense (semitransparent). US newspapers have longer format. We&#8217;ll have to take that in account. Every newspaper has its own format. Preserve it. Highlighted areas need to be stronger. Use multiply option in the fusion of the layer, and not transparency. I think you changed from layer after you coded the &#8220;mubarak photo&#8221; 6.3 nytimes, so the&#8230; <a href="https://blog.pageonex.com/2012/07/06/arab-spring-visualization-with-processing-inkscape/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
		
					<wfw:commentRss>https://blog.pageonex.com/2012/07/06/arab-spring-visualization-with-processing-inkscape/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
			</item>
		<item>
		<title>Scraping newspapers&#8217; names from Kiosko.net</title>
		<link>https://blog.pageonex.com/2012/06/28/scraping-newspapers-names-from-kiosko-net/</link>
					<comments>https://blog.pageonex.com/2012/06/28/scraping-newspapers-names-from-kiosko-net/#respond</comments>
		
		<dc:creator><![CDATA[pablo]]></dc:creator>
		<pubDate>Thu, 28 Jun 2012 05:50:17 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[Scraping]]></category>
		<guid isPermaLink="false">http://montera34.org/pageonex/?p=111</guid>

					<description><![CDATA[Rporres was visiting Cambridge last week, and after listening to one of the online meetings, he decided to jump in the project. By night he had finished the script for grabbing all the newspapers that are available in Kiosko.net. We will need this list soon You can check the code at https://gist.github.com/2970558 or the output (a csv file with the name, friendly url name, coauntry and country code of all the 377 newspapers) at http://brownbag.me:9001/p/pageonex-kiosko-newspaper-names. It&#8217;s written in&#8230; <a href="https://blog.pageonex.com/2012/06/28/scraping-newspapers-names-from-kiosko-net/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
		
					<wfw:commentRss>https://blog.pageonex.com/2012/06/28/scraping-newspapers-names-from-kiosko-net/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Thread&#8217;s date issue when selecting days in different months, suggestions?</title>
		<link>https://blog.pageonex.com/2012/06/22/threads-date-issue/</link>
					<comments>https://blog.pageonex.com/2012/06/22/threads-date-issue/#comments</comments>
		
		<dc:creator><![CDATA[pablo]]></dc:creator>
		<pubDate>Fri, 22 Jun 2012 05:32:45 +0000</pubDate>
				<category><![CDATA[meetings]]></category>
		<category><![CDATA[Scraping]]></category>
		<guid isPermaLink="false">http://montera34.org/pageonex/?p=93</guid>

					<description><![CDATA[After the user creates a thread, he selects starting date and end date which could span on more than one month. The problem is that the scraping script works on one month at a time, because I&#8217;ve found a difficulty to write a method that can take the start and end date in different months and calculated the number of days between them. Because of that the days at each month changes from one year to another, that doesn&#8217;t mean&#8230; <a href="https://blog.pageonex.com/2012/06/22/threads-date-issue/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
		
					<wfw:commentRss>https://blog.pageonex.com/2012/06/22/threads-date-issue/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
			</item>
		<item>
		<title>Update Scraping script to scrape from many sources</title>
		<link>https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/</link>
					<comments>https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/#comments</comments>
		
		<dc:creator><![CDATA[pablo]]></dc:creator>
		<pubDate>Wed, 20 Jun 2012 04:18:43 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[Scraping]]></category>
		<category><![CDATA[elpais]]></category>
		<category><![CDATA[kiosko]]></category>
		<category><![CDATA[nytimes]]></category>
		<category><![CDATA[ruby]]></category>
		<category><![CDATA[scraper]]></category>
		<guid isPermaLink="false">http://montera34.org/pageonex/?p=47</guid>

					<description><![CDATA[I&#8217;ve made some changes to the script to scrape from different sources (http://kiosko.net, http:/nytimes.com, http://elpais.com) and other sources can be added easily, for each source there are two methods, build_source_issues and save_source_issues, the first method is to construct the URI of the issue image based on some pattern which different from source to another, and the other method is to scrape the images and save them on the disk in their specific folders. I&#8217;ve wrote some comments to clear some parts of&#8230; <a href="https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
		
					<wfw:commentRss>https://blog.pageonex.com/2012/06/20/update-scraping-script-to-scrape-from-many-sources/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>First Scraping script for Kiosko.net</title>
		<link>https://blog.pageonex.com/2012/06/13/first-scrapping-script-for-kiosko-net/</link>
					<comments>https://blog.pageonex.com/2012/06/13/first-scrapping-script-for-kiosko-net/#respond</comments>
		
		<dc:creator><![CDATA[pablo]]></dc:creator>
		<pubDate>Wed, 13 Jun 2012 20:06:11 +0000</pubDate>
				<category><![CDATA[code]]></category>
		<category><![CDATA[Scraping]]></category>
		<category><![CDATA[kiosko]]></category>
		<category><![CDATA[newseum]]></category>
		<category><![CDATA[ruby]]></category>
		<category><![CDATA[scraper]]></category>
		<guid isPermaLink="false">http://montera34.org/pageonex/?p=31</guid>

					<description><![CDATA[Ahmd has been working on a scrapper in Ruby for the front Pages at Kiosko.net I&#8217;ve finished the scraping script, and it&#8217;s public on https://gist.github.com/2925910 to run the script just pass the file to ruby [ruby scraper.rb] and it will generate the folders (the directories is set for Linux, if you are on Windows you should modify them first), download the images(you can change the variable values in the get_issues method to get different newspapers), and write the&#8230; <a href="https://blog.pageonex.com/2012/06/13/first-scrapping-script-for-kiosko-net/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
		
					<wfw:commentRss>https://blog.pageonex.com/2012/06/13/first-scrapping-script-for-kiosko-net/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
